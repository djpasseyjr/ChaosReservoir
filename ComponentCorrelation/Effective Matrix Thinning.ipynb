{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy import integrate\n",
    "%run \"../HyperParameterOpt/GenerateExperiments/res_experiment.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Network Sparsity on the Effective Adjacency Matrix of a Trained Reservoir Computer\n",
    "\n",
    "Reservoir computer dynamics are governed by two equations:\n",
    "\n",
    "$ \\frac{d}{dt}\\mathbf{r}(t) = \\gamma[\\, -\\mathbf{r}(t) + \\text{tanh}\\big(\\mathbf{A}\\mathbf{r}(t) + \\sigma \\mathbf{W}_{\\text{in}}\\mathbf{u}(t)\\big) \\,]$\n",
    "\n",
    "$\\frac{d}{dt}\\hat{\\mathbf{r}}(t) = \\gamma[-\\hat{\\mathbf{r}}(t) + \\text{tanh}\\big(\\mathbf{A}\\hat{\\mathbf{r}}(t) + \\sigma \\mathbf{W}_{\\text{in}}\\mathbf{W}_{\\text{out}}\\hat{\\mathbf{r}}(t)\\big)$\n",
    "\n",
    "The first equation is used to train the reservoir. In this equation, the nodes of the reservoir interact according to an adjacency matrix $\\mathbf{A}$ and are perturbed by a desired output signal $\\mathbf{u}$ transformed by $W_{\\text{in}}$. The $-\\mathbf{r}(t)$ term introduces an individual node activation decay when $\\gamma$ is positive. Overall this means that the nodes in the reservoir naturally decay, but are excited by the combination of $\\mathbf{A} \\mathbf{r}(t)$ and $W_{in} \\mathbf{u}(t)$. The hyperbolic tangent function is used to threshold exitiations from node interactions and stimulation from the desired output signal by ensuring that they never leave the interval $(-1,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the first equation is solved for some time interval $(0, T)$. The solution $\\mathbf{r}(t)$ is then projected onto $\\mathbf{u}(t)$ via a linear mapping $W_{\\text{out}}$. This mapping is the mapping that minimizes $||\\mathbf{u}(t) - W_{\\text{out}} \\mathbf{r}(t)||_2 + \\alpha || W_{\\text{out}} ||_2$ for some amount of regularization ($\\alpha$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the reservoir computer is governed by the second equation. At this point it is no longer dependent on the desired output signal $\\mathbf{u}(t)$. It becomes a stand-alone dynamical system. \n",
    "\n",
    "However, from the network science perspective the structure of the reservoir network changes drastically after training. Where previously, reservoir node interactions were governed by $A$ and then stimulated by $W_{in} \\mathbf{u}$, they are now governed by $\\mathbf{A}\\hat{\\mathbf{r}}(t) + \\sigma \\mathbf{W}_{\\text{in}}\\mathbf{W}_{\\text{out}}\\hat{\\mathbf{r}}(t)$, making the effective adjacency matrix $\\mathbf{A} + \\sigma \\mathbf{W}_{\\text{in}}\\mathbf{W}_{\\text{out}}$.\n",
    "\n",
    "A few limited experiments found that $ \\mathbf{W}_{\\text{in}}\\mathbf{W}_{\\text{out}} $ did not have a clear component structure. But further work is needed to investigate the structure of the effective adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFF_EQ_PARAMS = {\n",
    "                  \"x0\": [-20, 10, -.5],\n",
    "                  \"begin\": 0,\n",
    "                  \"end\": 85,\n",
    "                  \"timesteps\": 85000,\n",
    "                  \"train_per\": .889,\n",
    "                  \"solver\": lorenz_equ,\n",
    "                  \"clip\": 40\n",
    "                 }\n",
    "\n",
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-6,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 2.0,\n",
    "              \"gamma\": 5,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_percent_edges(A, p):\n",
    "    return remove_edges(A, floor(p * np.sum(A != 0)))\n",
    "\n",
    "def train_rc(topo, remove_p=0.0, spect_rad=2.0, topo_p=None, n=2500):\n",
    "    prms = deepcopy(RES_PARAMS)\n",
    "    diff_eq_params = deepcopy(DIFF_EQ_PARAMS)\n",
    "    # Make rc\n",
    "    A = remove_percent_edges(generate_adj(topo, topo_p, n=n), remove_p)\n",
    "    \n",
    "    prms[\"spect_rad\"] = spect_rad\n",
    "    rc = ResComp(A, **prms)\n",
    "    # Generate random orbit\n",
    "    diff_eq_params[\"x0\"] = random_lorenz_x0()\n",
    "    train_t, test_t, u = rc_solve_ode(diff_eq_params)\n",
    "    err = rc.fit(train_t, u)\n",
    "    pred = how_long_accurate(u(test_t), rc.predict(test_t), tol=TOL)\n",
    "    return rc, err, pred\n",
    "\n",
    "def effective_adj(rc):\n",
    "    return rc.res + rc.sigma * rc.W_in @ rc.W_out\n",
    "    \n",
    "def plot_matrix(A, log=False, title=\"Effective Adj Matrix\"):\n",
    "    if log:\n",
    "        A = np.log(np.abs(A))\n",
    "        title += \" (Pictured: log(A))\"\n",
    "    plt.imshow(A, cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_rc(topo, remove_p=0.0, spect_rad=2.0, topo_p=None, n=2500):\n",
    "    prms = deepcopy(RES_PARAMS)\n",
    "    diff_eq_params = deepcopy(DIFF_EQ_PARAMS)\n",
    "    # Make rc\n",
    "    A = remove_percent_edges(generate_adj(topo, topo_p, n=n), remove_p)\n",
    "    \n",
    "    prms[\"spect_rad\"] = spect_rad\n",
    "    rc = ResComp(A, **prms)\n",
    "    # Generate random orbit\n",
    "    diff_eq_params[\"x0\"] = random_lorenz_x0()\n",
    "    train_t, test_t, u = rc_solve_ode(diff_eq_params)\n",
    "    err = rc.fit(train_t, u)\n",
    "    pred = how_long_accurate(u(test_t), rc.predict(test_t), tol=TOL)\n",
    "    return rc, pred, u, test_t\n",
    "\n",
    "def predict(rc, t, eadj = effective_adj(rc), u_0=None, r_0=None, return_states=False):\n",
    "    \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "    \"\"\"\n",
    "    if not rc.is_trained:\n",
    "        raise Exception(\"Reservoir is untrained\")\n",
    "\n",
    "    # Reservoir prediction ode\n",
    "    def res_pred_f(r,t):\n",
    "        return rc.gamma*(-1*r + rc.activ_f(eadj @ r))\n",
    "    # end\n",
    "    if r_0 is None and u_0 is None:\n",
    "        r_0  = rc.state_0\n",
    "    # end\n",
    "    elif r_0 is None and u_0 is not None:\n",
    "        r_0 = rc.W_in @ u_0\n",
    "    # end\n",
    "    pred = integrate.odeint(res_pred_f, r_0, t)\n",
    "    if return_states:\n",
    "        return rc.W_out @ pred.T, pred.T\n",
    "    return rc.W_out @ pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-6,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 4,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 0.1,\n",
    "              \"gamma\": 2,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"barab1\",remove_p=.94)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1786, 0), (1786, 3.088e-05), (1786, 4e-05), (1786, 5.216e-05), (1786, 6.752e-05), (1784, 8.832e-05), (1782, 0.00011136), (1777, 0.00014096), (1776, 0.00017936), (1780, 0.00022352), (1772, 0.00028352), (1788, 0.00035888), (1777, 0.00046064), (1802, 0.00058816), (1766, 0.00073584), (1136, 0.00093712), (1776, 0.00118256), (1754, 0.0014832), (1875, 0.0018408), (1247, 0.002248), (1917, 0.0027488)]\n"
     ]
    }
   ],
   "source": [
    "predictions_bara1 = [(pred,0)]\n",
    "for thin in np.logspace(-5,-3,20):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)<=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)>thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions_bara1.append((pred1,percent))\n",
    "print(predictions_bara1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-6,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 4,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 0.1,\n",
    "              \"gamma\": 5,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"barab2\",remove_p=.84)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(788, 0), (788, 4.24e-05), (786, 5.36e-05), (788, 7.056e-05), (791, 9.104e-05), (789, 0.00011632), (789, 0.0001456), (792, 0.00018144), (796, 0.00022784), (810, 0.00029136), (849, 0.0003624), (1355, 0.00046128), (1208, 0.00058512), (1191, 0.00075024), (731, 0.0009648), (681, 0.00121664), (735, 0.00156992), (610, 0.00199744), (527, 0.0025544), (461, 0.0032536), (443, 0.00417728)]\n"
     ]
    }
   ],
   "source": [
    "predictions_bara2 = [(pred,0)]\n",
    "for thin in np.logspace(-5,-3,20):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)<=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)>thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions.append((pred1,percent))\n",
    "print(predictions_bara2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-4,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 4,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 1.,\n",
    "              \"gamma\": 5,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"erdos\",topo_p=2,remove_p=.96)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2529, 0), (2524, 0.00018016), (2522, 0.00022944), (2518, 0.00028672), (2520, 0.0003664), (2527, 0.0004648), (2510, 0.00058688), (2546, 0.00075216), (2495, 0.00095264), (2523, 0.0012104), (2472, 0.0015368), (4584, 0.00196704), (4995, 0.00250848), (4995, 0.00318192), (2417, 0.00405888), (2462, 0.00517952), (2483, 0.00657904), (2337, 0.00839616), (2277, 0.01075104), (2312, 0.01372464), (2184, 0.01745952)]\n"
     ]
    }
   ],
   "source": [
    "predictions_erdos2 = [(pred,0)]\n",
    "for thin in np.logspace(-5,-3,20):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)<=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)>thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions_erdos2.append((pred1,percent))\n",
    "print(predictions_erdos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joebo\\WebbWork\\ReservoirSpecialization\\rescomp\\ResComp.py:167: UserWarning: Spectral radius of reservoir is close to zero. Edge weights will not be scaled\n",
      "  warn(\"Spectral radius of reservoir is close to zero. Edge weights will not be scaled\")\n",
      "C:\\Users\\joebo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.94251e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-8,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 3,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 1.0,\n",
    "              \"gamma\": 5.0,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"random_digraph\",remove_p=.96,topo_p=2)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(703, 0), (705, 3.84e-06), (687, 5.76e-06), (770, 9.6e-06), (620, 1.568e-05), (596, 2.496e-05), (599, 4.16e-05), (506, 6.752e-05), (466, 0.00011792), (474, 0.00019696), (448, 0.00032656)]\n"
     ]
    }
   ],
   "source": [
    "predictions_random_digraph = [(pred,0)]\n",
    "for thin in np.logspace(-5,-3,10):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)<=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)>thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions_random_digraph.append((pred1,percent))\n",
    "print(predictions_random_digraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joebo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.75022e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-8,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 4,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 2.,\n",
    "              \"gamma\": 5,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"watts2\",topo_p=.5,remove_p=.98)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2394, 0), (2392, 2.56e-06), (2306, 8.32e-06), (2171, 2.336e-05), (1363, 5.248e-05), (706, 0.0001384), (496, 0.00034304)]\n"
     ]
    }
   ],
   "source": [
    "predictions_watts2 = [(pred,0)]\n",
    "for thin in np.logspace(-5,-3,6):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)<=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)>thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions_watts2.append((pred1,percent))\n",
    "print(predictions_watts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3342\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-6,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 4,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 2.,\n",
    "              \"gamma\": 5,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"watts4\",topo_p=.1,remove_p=.99)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3342, 0), (3348, 2.208e-05), (3335, 2.928e-05), (3323, 3.872e-05), (3320, 5.024e-05), (3343, 6.016e-05), (3291, 7.92e-05), (3314, 0.00010064), (3244, 0.00012544), (3494, 0.00016128), (3344, 0.0002048), (3293, 0.0002632), (1179, 0.00033056), (1183, 0.00042), (3279, 0.00053504), (1093, 0.00067968), (1048, 0.00087488), (1082, 0.00110944), (869, 0.00141664), (879, 0.00181296), (848, 0.0023176)]\n"
     ]
    }
   ],
   "source": [
    "predictions_watts4 = [(pred,0)]\n",
    "for thin in np.logspace(-5,-3,20):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)<=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)>thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions_watts4.append((pred1,percent))\n",
    "print(predictions_watts4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if removing largest edges is effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    }
   ],
   "source": [
    "RES_PARAMS = {\n",
    "              \"uniform_weights\": True,\n",
    "              \"solver\": \"ridge\",\n",
    "              \"ridge_alpha\": 1e-6,\n",
    "              \"signal_dim\": 3,\n",
    "              \"network\": \"random graph\",\n",
    "              #\"mean_degree\": 4,\n",
    "              \"res_sz\": 15,\n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .4,\n",
    "              \"spect_rad\": 0.1,\n",
    "              \"gamma\": 5,\n",
    "              \"sigma\": .14,\n",
    "              \"sparse_res\": True,\n",
    "             }\n",
    "rc, pred, u, test_t = test_train_rc(\"barab2\",remove_p=.84)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(907, 0), (3, 0.0096808), (2, 0.00291536), (1, 0.00109424), (3, 0.00049344), (4, 0.00024176), (3, 0.00012224), (3, 5.568e-05), (5, 1.136e-05), (50, 1.6e-07)]\n"
     ]
    }
   ],
   "source": [
    "predictions_bara = [(pred,0)]\n",
    "for thin in np.linspace(3,np.max(effective_adj(rc)),9):\n",
    "    eadj = effective_adj(rc)\n",
    "    percent = np.sum(np.abs(eadj)>=thin)/np.size(eadj)\n",
    "    eadj = np.where(np.abs(eadj)<thin,eadj,0)\n",
    "    pred1 = how_long_accurate(u(test_t), predict(rc,test_t,eadj), tol=TOL)\n",
    "    predictions_bara.append((pred1,percent))\n",
    "print(predictions_bara)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
